{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8d7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA  \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac21ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 1: Cargar y preprocesar los datos\n",
    "\n",
    "def load_train_test_data():\n",
    "    train_df = pd.read_csv(\"../files/input/train_data.csv.zip\", index_col=False)\n",
    "    test_df = pd.read_csv(\"../files/input/test_data.csv.zip\", index_col=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocess_data(train_df, test_df):\n",
    "\n",
    "    #Remover ID\n",
    "    train_df.drop(columns=[\"ID\"], inplace=True)\n",
    "    test_df.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "    #Renombrar default\n",
    "    train_df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "    test_df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "\n",
    "    #Remover NaNs\n",
    "    train_df.dropna(inplace=True)\n",
    "    test_df.dropna(inplace=True)\n",
    "\n",
    "    #Corregir educacion\n",
    "    train_df[\"EDUCATION\"] = train_df[\"EDUCATION\"].apply(lambda x: 4 if x > 4 else x)\n",
    "    test_df[\"EDUCATION\"] = test_df[\"EDUCATION\"].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "    #Remover no disponibles de marriage y education\n",
    "    train_df =  train_df.query(\"MARRIAGE != 0 & EDUCATION != 0\")\n",
    "    test_df =  test_df.query(\"MARRIAGE != 0 & EDUCATION != 0\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "train, test = load_train_test_data()\n",
    "train, test = preprocess_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73bc1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entrenamiento: (20953, 23) (20953,)\n",
      "Dimensiones del conjunto de prueba: (8979, 23) (8979,)\n"
     ]
    }
   ],
   "source": [
    "#Paso 2: Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "def make_train_test_split(train_df, test_df):\n",
    "\n",
    "    #Usar la columna default como target\n",
    "    X_train = train_df.drop(columns=[\"default\"])\n",
    "    X_test = test_df.drop(columns=[\"default\"])\n",
    "    y_train = train_df[\"default\"]\n",
    "    y_test = test_df[\"default\"]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = make_train_test_split(train, test)\n",
    "\n",
    "#Verficar las dimensiones de los conjuntos\n",
    "print(\"Dimensiones del conjunto de entrenamiento:\", X_train.shape, y_train.shape)\n",
    "print(\"Dimensiones del conjunto de prueba:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "134cf39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 3: Construir el pipeline de preprocesamiento y modelado\n",
    "\n",
    "def make_pipeline():\n",
    "\n",
    "    #Columnas categóricas y numéricas\n",
    "    categorical_cols = [\"MARRIAGE\", \"EDUCATION\", \"SEX\"]\n",
    "    numerical_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(), categorical_cols),\n",
    "            (\"num\", StandardScaler(), numerical_cols),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    selectkbest_feature = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"transformer\", transformer),\n",
    "            (\"pca\", PCA()),\n",
    "            (\"selectkbest\", selectkbest_feature),\n",
    "            (\"svc\", SVC()),\n",
    "        ],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "estimator = make_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665be96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Buscar hiperparámetros óptimos usando GridSearchCV\n",
    "\n",
    "def perform_grid_search(estimator, X_train, y_train):\n",
    "\n",
    "    param_grid = {\n",
    "        \"pca__n_components\": [20, 21],\n",
    "        \"selectkbest__k\": [12],\n",
    "        \"svc__kernel\": [\"rbf\"],\n",
    "        \"svc__gamma\": [0.1],\n",
    "    }\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "model = perform_grid_search(estimator, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a0a0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Guardar el modelo\n",
    "\n",
    "# Verificar existencia del directorio\n",
    "os.makedirs(\"../files/models/\", exist_ok=True)\n",
    "\n",
    "# Guardar el modelo GridSearchCV completo\n",
    "with gzip.open(\"../files/models/model.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3d6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6 y 7: Calcular y guardar métricas de evaluación\n",
    "\n",
    "def save_evaluation_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Realizar predicciones\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular métricas de confusión\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    results =[\n",
    "        \n",
    "        {\n",
    "            'type': 'metrics',\n",
    "            'dataset': 'train',\n",
    "            'precision': precision_score(y_train, y_train_pred, zero_division=0),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_train, y_train_pred),\n",
    "            'recall': recall_score(y_train, y_train_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_train, y_train_pred, zero_division=0) \n",
    "        },\n",
    "        {\n",
    "            'type': 'metrics',\n",
    "            'dataset': 'test',\n",
    "            'precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_test, y_test_pred, zero_division=0) \n",
    "        },\n",
    "        {\n",
    "            'type': 'cm_matrix',\n",
    "            'dataset': 'train',\n",
    "            'true_0': {'predicted_0': int(cm_train[0][0]), 'predicted_1': int(cm_train[0][1])},\n",
    "            'true_1': {'predicted_0': int(cm_train[1][0]), 'predicted_1': int(cm_train[1][1])}\n",
    "        },\n",
    "        {\n",
    "            'type': 'cm_matrix',\n",
    "            'dataset': 'test',\n",
    "            'true_0': {'predicted_0': int(cm_test[0][0]), 'predicted_1': int(cm_test[0][1])},\n",
    "            'true_1': {'predicted_0': int(cm_test[1][0]), 'predicted_1': int(cm_test[1][1])}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Verificar existencia del directorio\n",
    "    os.makedirs(\"../files/output\", exist_ok=True)\n",
    "\n",
    "    # Guardar métricas en un archivo JSON\n",
    "    with open(\"../files/output/metrics.json\", \"w\") as file:\n",
    "        for record in results:\n",
    "            json.dump(record, file)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "save_evaluation_metrics(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a0f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
